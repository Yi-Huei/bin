{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "本篇參考網站為:[Regularization of Linear Models with SKLearn](https://medium.com/coinmonks/regularization-of-linear-models-with-sklearn-f88633a93a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文主要在探討Regularization之重要性，Regularization主要目的是降低Overfit，其原因為資料集中有許多特徵X並不會影響結果y，然在進行運算時，全部都考慮進來了。\n",
    "\n",
    "以鐵達尼號為例，若我們將乘客姓名也列入X中，來判定乘客的生存率，電腦在運算時，一定會加入此因素，所以在訓練資料的準確度會很高，但測試資料就完全不准，當然我們知道乘客姓名與生存率並沒有關係，但是資料集往往是很複雜的，我們很難知道哪些X是不會影響y的。\n",
    "\n",
    "Regularization便是幫助我們找出不會影響y的X，並將其權重(Weight)設為0。常見的Regularization有\n",
    "- L1\n",
    "- L2\n",
    "- Group Lasso\n",
    "\n",
    "本篇以波斯頓房價為例，分別進行:\n",
    "1. 未做Regularization之一次回歸\n",
    "2. 強化特徵之二次回歸\n",
    "3. L2 之二次回歸\n",
    "4. L1 之一次回歸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "ds = datasets.load_boston()\n",
    "X = pd.DataFrame(ds.data, columns=ds.feature_names) # axis=0刪除列，axis=1刪除欄\n",
    "y = ds.target\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切割資料，本次設定random_state=42，保證每次重新執行可以得到相同分配\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、一次線性迴歸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.7434997532004697\n",
      "Test score: 0.7112260057484907\n",
      "RMSE: 4.638689926172841\n",
      "MAE: 21.517444231177393\n",
      "判定係數(coefficient of determination) ： 0.7112260057484907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "\n",
    "# 演算法: 線性迴歸\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lr_model.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lr_model.score(X_test, y_test)))\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print('RMSE: {}'.format(rmse))\n",
    "\n",
    "mae = mean_squared_error(y_test, y_pred)\n",
    "print('MAE: {}'.format(mae))\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('判定係數(coefficient of determination) ： {}'.format(r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、強化特徵後 二次回歸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 將所有特徵進行平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有特徵進行平方\n",
    "X['CRIM'] = X['CRIM'] ** 2\n",
    "X['ZN'] = X['ZN'] ** 2\n",
    "X['INDUS'] = X['INDUS'] ** 2\n",
    "X['CHAS'] = X['CHAS'] ** 2\n",
    "X['NOX'] = X['NOX'] ** 2\n",
    "X['RM'] = X['RM'] ** 2\n",
    "X['AGE'] = X['AGE'] ** 2\n",
    "X['DIS'] = X['DIS'] ** 2\n",
    "X['RAD'] = X['RAD'] ** 2\n",
    "X['TAX'] = X['TAX'] ** 2\n",
    "X['PTRATIO'] = X['PTRATIO'] ** 2\n",
    "X['B'] = X['B'] ** 2\n",
    "X['LSTAT'] = X['LSTAT'] ** 2\n",
    "\n",
    "#split into training and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 二次回歸_pipeline\n",
    "本次利用pipeline的方法處裡，簡化程式模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.932111445812428\n",
      "Test score: -0.38111982184256443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#將流程寫入串列 step中\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),   #標準化\n",
    "    ('poly', PolynomialFeatures(degree=2)),  #二次方程式\n",
    "    ('model', LinearRegression())  #線性迴歸\n",
    "]\n",
    "\n",
    "#透過 pipeline進行訓練\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#取得訓練資料與測試資料的分數\n",
    "print('Training score: {}'.format(pipeline.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**訓練分數很高，測試分數很低---->發生過度擬和(over fit)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  四、L2\n",
    "Regularization L2 在scikit learn模組中為Ridge  \n",
    "[scikit learn Ridge官方網站](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "重要參數說明:\n",
    "1. alpha= : 強度調整\n",
    "2. fit_intercept= 是否取得截距(常數)項"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 訓練並取得分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9129776798768119\n",
      "Test Score: 0.8087177812604328\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),     #特徵工程:標準化\n",
    "    ('poly', PolynomialFeatures(degree=2)),   #演算法:2次線性回歸\n",
    "    ('model', Ridge(alpha=10, fit_intercept=True))  #Ridge為Regularization L2，alpha可調整強度\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training Score: {}'.format(ridge_pipe.score(X_train, y_train)))\n",
    "print('Test Score: {}'.format(ridge_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**訓練分數降低，但測試分數提高。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 查看模型係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -3.66315696e-01,  1.21657218e-01,  6.38586107e-02,\n",
       "        8.27179076e-02, -6.63967925e-01,  3.70271826e+00, -9.60609314e-01,\n",
       "       -1.12372931e+00,  1.94687748e-01, -7.82988469e-01, -9.61876883e-01,\n",
       "        2.44253647e-01, -3.35623909e+00,  1.74183971e-01,  1.18178838e-01,\n",
       "       -3.35914182e-01,  5.36023618e-01, -2.22485850e-01,  3.30465786e-01,\n",
       "       -9.87328093e-02,  4.48285405e-01, -6.66978293e-01, -4.73895406e-01,\n",
       "       -1.83812503e-01, -2.96572857e-01,  1.12781504e+00,  3.53213539e-01,\n",
       "       -1.75038137e-01, -6.89558329e-02,  2.56927155e-01,  2.59100527e-02,\n",
       "       -1.14235586e-01, -5.46849217e-01, -1.17776314e-01,  5.06747769e-01,\n",
       "        2.02735549e-01,  3.34665843e-03,  1.78379329e-01,  4.90569748e-01,\n",
       "        5.30537882e-01,  6.40761095e-01,  1.10111560e+00,  5.53211699e-01,\n",
       "        6.18675359e-01, -9.89232679e-02, -2.54428582e-01, -3.36082217e-01,\n",
       "        6.64932879e-02, -4.21419883e-01,  2.70509728e-01, -1.40989983e+00,\n",
       "       -6.53242522e-01,  1.58757704e-01, -5.00484966e-02,  7.11372989e-01,\n",
       "        1.31062853e+00, -5.35703034e-01,  5.82280004e-01, -7.22716897e-02,\n",
       "       -6.16245984e-01, -1.04896796e+00, -7.83960422e-01,  4.30179402e-01,\n",
       "       -7.24357698e-01, -4.52274605e-02, -8.15338951e-01, -4.45377704e-01,\n",
       "        5.28309512e-01,  4.24965435e-01, -1.09598469e+00, -2.14250038e-01,\n",
       "       -1.13532412e+00, -1.02439665e+00, -1.05107789e+00, -5.63825038e-01,\n",
       "        3.70075543e-01,  8.69091540e-01,  1.81278859e-01,  7.14339076e-01,\n",
       "        5.28528168e-01, -1.75451811e-02, -3.54933364e-01, -1.37474652e+00,\n",
       "        6.73034347e-01,  1.29110910e-01, -4.64802590e-01,  5.38738714e-03,\n",
       "       -2.27576910e-01,  5.21913270e-01, -1.86861366e-01,  4.90321602e-01,\n",
       "        5.67341730e-01,  1.66006562e-01, -1.36471716e+00,  1.31294583e-01,\n",
       "        1.07156691e+00, -5.01552354e-01, -7.89612976e-01, -6.64799982e-02,\n",
       "       -2.51083778e-01,  3.02401428e-01, -4.63176907e-01,  4.14717430e-02,\n",
       "        1.29991392e+00])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看pipeline模型的係數\n",
    "ridge_pipe['model'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**但所有係數非0，模型複雜**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、L1 \n",
    "Regularization L1 又稱Lasso Regression，在Scikit learn中為Lesso  \n",
    "[Scikit learn Lesso參考網站](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 訓練並取得分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.845169139561712\n",
      "Test score: 0.8063938085973288\n"
     ]
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.3, fit_intercept=True))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lasso_pipe.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lasso_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**訓練分數降低，但測試分數提高。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 查看模型係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  3.44000388, -0.1721537 , -0.        , -0.        ,\n",
       "       -0.        , -1.22578904,  0.        , -3.83052518, -0.01314298,\n",
       "        0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.21162576, -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.09557567,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.30572658, -0.32548581, -0.        ,  0.        , -0.        ,\n",
       "        0.        ,  0.870703  ,  0.        ,  0.        , -0.        ,\n",
       "       -0.27615318, -0.33576005,  0.        ,  0.2731334 , -0.29392616,\n",
       "       -0.        , -0.        , -0.        , -0.        ,  0.37432376,\n",
       "       -0.        ,  0.        , -1.80087185, -0.        , -0.56733826,\n",
       "        0.        , -0.        ,  0.09750964,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.07856643, -0.        ,\n",
       "        0.        ,  0.        ,  0.20998698, -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        , -0.        , -0.96885439,\n",
       "       -0.        ,  0.        , -0.        , -0.42994494, -0.        ,\n",
       "       -0.        , -0.        , -0.26572841, -0.        ,  0.82320999])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_pipe['model'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**發現多數係數為0，表L1可以簡化模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**結論:L1 test score 最高，且模型簡單**\n",
    "\n",
    "最後針對Overfit問題之解決方法，除了本章Regularization外，在上一章\"Breast Cancer特徵工程\"中，特徵選取與特徵萃取也可以解決此問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全部程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一次線性回歸訓練分數:  0.7434997532004697\n",
      "一次線性回歸測試分數: 0.7112260057484907\n",
      "所有特徵進行平方後進行2次線性迴歸訓練分數: 0.932111445812428\n",
      "所有特徵進行平方後進行2次線性迴歸測試分數: -0.38111982184256443\n",
      "L2 訓練分數: 0.9129776798768119\n",
      "L2 測試分數: 0.8087177812604328\n",
      "L1 訓練分數: 0.845169139561712\n",
      "L1 測試分數: 0.8063938085973288\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n",
    "\n",
    "ds = datasets.load_boston()\n",
    "X = pd.DataFrame(ds.data, columns=ds.feature_names) # axis=0刪除列，axis=1刪除欄\n",
    "y = ds.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3) #實際專案可拿掉random_state\n",
    "\n",
    "# 演算法: 線性迴歸\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "print('一次線性回歸訓練分數: ',lr_model.score(X_train, y_train))\n",
    "print('一次線性回歸測試分數:',lr_model.score(X_test, y_test))\n",
    "\n",
    "# 所有特徵進行平方後進行2次線性迴歸\n",
    "X['CRIM'] = X['CRIM'] ** 2\n",
    "X['ZN'] = X['ZN'] ** 2\n",
    "X['INDUS'] = X['INDUS'] ** 2\n",
    "X['CHAS'] = X['CHAS'] ** 2\n",
    "X['NOX'] = X['NOX'] ** 2\n",
    "X['RM'] = X['RM'] ** 2\n",
    "X['AGE'] = X['AGE'] ** 2\n",
    "X['DIS'] = X['DIS'] ** 2\n",
    "X['RAD'] = X['RAD'] ** 2\n",
    "X['TAX'] = X['TAX'] ** 2\n",
    "X['PTRATIO'] = X['PTRATIO'] ** 2\n",
    "X['B'] = X['B'] ** 2\n",
    "X['LSTAT'] = X['LSTAT'] ** 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),   #標準化\n",
    "    ('poly', PolynomialFeatures(degree=2)),  #二次方程式\n",
    "    ('model', LinearRegression())  #線性迴歸\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('所有特徵進行平方後進行2次線性迴歸訓練分數: {}'.format(pipeline.score(X_train, y_train)))\n",
    "print('所有特徵進行平方後進行2次線性迴歸測試分數: {}'.format(pipeline.score(X_test, y_test)))\n",
    "\n",
    "# L2\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),     #特徵工程:標準化\n",
    "    ('poly', PolynomialFeatures(degree=2)),   #演算法:2次線性回歸\n",
    "    ('model', Ridge(alpha=10, fit_intercept=True))  #Ridge為Regularization L2，alpha可調整強度\n",
    "]\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "print('L2 訓練分數: {}'.format(ridge_pipe.score(X_train, y_train)))\n",
    "print('L2 測試分數: {}'.format(ridge_pipe.score(X_test, y_test)))\n",
    "\n",
    "# L1\n",
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.3, fit_intercept=True))\n",
    "]\n",
    "lasso_pipe = Pipeline(steps)\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "print('L1 訓練分數: {}'.format(lasso_pipe.score(X_train, y_train)))\n",
    "print('L1 測試分數: {}'.format(lasso_pipe.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
